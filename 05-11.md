
#PAA
#Professor Fabrício

### Single Source Shortest Paths

Revisão do single source shortest path:

Grafo não direcionado:
 - BFS - O(V+E)

Com arestas de pesos não negativos:
 - Dijkstra - O(V log(V)+E) using Fibbonaci Heap

Com arestas podendo ter pesos negativos:
 - Bellman Ford - O(V E)

### All-Pairs Shortest Paths

Encontre o caminho mínimo para cada par de vertices.  
(Por exemplo para encontrar o grau de separação máximo entre pessoas
no twitter)

Uma abordagem possível: 
Execute um algoritmo de um vertice para todos os outros V vezes.
Dessa forma conseguirá todos os pares possíveis de vertices.

1° Arestas não negativas: Use Dijkstra
- Complexidade:
 - O(V³)
 - O(VE lg V) with binary heap
 - O(V² lg V + VE) with Fibonacci heap

2° Arestas negativas: Use Bellman-Ford
- Complexidade: O(V²+E) = O(V<sup>4</sup>)

Nessa aula discutiremos 3 algoritmos que também resolvem esse problema:
  
- "Repeated Squaring": O(V³ log(V))
- Floyd-Warshall: O(V³)
- Johnson's: O( V² log(V) + VE )
  
### Repeated Squaring Algorithm

Esse algoritmo calcula todas as distancias com número de arestas
`m` antes de calcular todas as distâncias de comprimento `m+1`. A
parte dinâmica do algoritmo utiliza as distância com `m` arestas
para calcular as distâncias com `m+1` arestas dessa forma melhorando
a performance.

Seja o grafo dado em uma matrix de adjacencia com Wij sendo o peso de cada aresta i,j:

```
W = (Wij)
```

Seja Dij(m) = peso do caminho mínimo entre dois vertices i,j contendo no máximo `m` arestas.

```
Dij = { 0 if i=j
      { infinito, caso contrário

Dij(m) = min (Dij(m-1), min { Dik(m-1) + Wkj})

or

Dij(m) = min <= k <= n { Dik (m-1) + Wjk}, since Wjj=0.
```

O algoritmo funciona realizando operações sobre a matriz W repetidamente.

Começando com a matriz `MD[1] = W`, repita o calculo de distâncias para todos
os vertices com caminhos de `m` arestas onde `MD[m] = (Dij(m), para todo ij)`

```python
def repeatedSquare(W):
  # Número de vertices:
  n = len(W)
  
  MD[1] = W

  for m from 2 to n-1:
    MD[m] = extend(D[m-1], W)
  
  return MD[n-1]

def extend(MD, W):
  # Número de vertices:
	n = len(W)

  # Matriz extendida:
  extMD = [][]
  
  # Para todo i,j inclusive com i=j:
  for i from 1 to n:
    for j from 1 to n:

      # Calcule o menor caminho entre os dois com uma aresta a mais:
      extMD[i][j] = infinito
      for k from 1 to n:
        if( extMD[i][j] > MD[i][k] + W[k][j])
          extMD[i][j] = MD[i][k] + W[k][j]
```
Complexidade no tempo: O(V<sup>4</sup>)

Note a semelhança do método `extend` com uma multiplicação de matrizes
onde para cada i,j da matriz final é preciso iterar por uma linha
de uma matriz A e uma coluna de uma matriz B, no caso do extend A=MD e B=W.

A única diferença é o calculo realizado que não é uma multiplicação mas sim um mínimo.

**Otimizações:**

O algoritmo pode ser otimizado de duas formas:

1. O tempo de execução pode ser melhorado para O(V<sup>3</sup> log(V))
   se voce calcular as matrizes em potencias de 2, daí o nome
   "Repeated Squaring":

   - MD[2] = extend(W, W)
   - MD[4] = extend(MD[2], MD[2])
   - MD[8] = extend(MD[4], MD[4])
   - ...
   - MD[m] = extend(MD[m/2], MD[m/2])

2. Pode-se otimizar o algoritmo para utilizar apenas duas matrizes
   de forma que a complexidade no espaço seja apenas O(V²)

### Floyd-Warshall Algorithm

*Esse é o algoritmo mais importante segundo o professor*

Este algoritmo também é dinâmico mas funciona de forma diferente.

A matriz `MD[0] = W`, assim como no algoritmo anterior, porém para
cada iteração o que será feito é adicionar um vértice como candidato
a vertice intermédiário para formar um caminho.

Dessa forma `MD[k] = (Dij(k) para todo i,j)`, e `Dij(k)` = peso do caminho mínimo entre os vertices `i,j`
onde os vertices intermediarios do caminho se restrigem aos vertices: `1..k`

Ou seja cada iteração corresponde à inserção de um novo vertice
e na verificação de todos os caminhos que poderiam lucrar em passar por esse vertice.

O objetivo do algoritmo é encontrar `MD[n]`, ou seja o conjunto de todos os melhores caminhos
com todos os vertices do grafo incluidos.

A equação de recursividade do algoritmo pode ser dada por:

```
Dij(k) = { Wij if k=0
         { min(Dij(k-1), Dik(k-1) + Dkj(k-1) if k>=1
```

O pseudocódigo do algoritmo é simples em comparação com o outro método:

```
def floydWarshall(W): 
  n = len(W);
  MD[0] = W;
  
  # For each inserted node:
  for k from 1 to n:
    # For each other pair of nodes on the graph:
    for i from 1 to n:
      for j from 1 to n:
        # If the path thru the new node is faster than the old path:
        if MD[k][i][j] > MD[k-1][i][k] + MD[k-1][k][j]:
          # Set the new path as the best path found:
          MD[k][i][j] = MD[k-1][i][k] + MD[k-1][k][j]
  
  return MD[n]
```

Complexidade no tempo: O(V³)

O algoritmo pode ser melhorado para utilizar apenas duas matrizes mantendo
a complexidade no espaço em O(V²), o que é desejável.

O algoritmo também pode ser modificado para retornar a matriz de precedessores junto
com a resposta permitindo recuperar os caminhos mínimos e não apenas as distancias mínimas.

### Johnson's Algorithm

Esse algoritmo utiliza o Bellman-Ford e o Dijkstra de forma inteligente
para resolver o problema em `O(V² log(V) + V E)`.

Esse algoritmo é portanto mais eficiente que o Floyd-Warshall quando o grafo é esparso,
porém esse método não funcionaria em um grafo com pesos negativos nas arestas.

A idéia interessante deste algoritmo é um método de reponderar os pesos das arestas
de forma que não hajam mais arestas negativas e os menores caminhos permaneçam os mesmos;
ou seja, sem permitir que o ponderamento altere o problema original.

O método de Johnson para realizar esse ponderamento é feito da seguinte forma:

1. Coloca-se um novo vertice `S` no grafo, ele se liga a todos demais vertices
   com arestas de peso 0.
2. Coloque novos pesos nas demais arestas do grafo com a seguinte regra:  
   `Wij = Wij + Dsi - Dsj`,  
   Onde `Wij` são os pesos e `Dij` são as distancias mínimas.

Para obter Dsi e Dsj é preciso executar o Bellman-Ford com raiz em S.

Após executar o Bellman-Ford em O(V E) podemos em O(E) reponderar todas as arestas.

Após a reponderação podemos executar o Dijkstra em com raiz em cada um dos vertices
em O(V² log(V) + V E) de forma a obtermos as distancias mínimas entre todos
os pares de vertices.

A complexidade final fica O(V² log(V) + V E) que é o custo de aplicar o Dijkstra V vezes.

```python

def johnsons(G):
  Gcopy = G
  
  # Crie o vertice s:
  Gcopy.V += s
  for v in Gcopy.V:
    Gcopy.E += (s,v)
    w(s,v) = 0
  
  # Calculate the Dsv for all nodes `v`:
  dists = BellmanFord(Gcopy, s)
  if dists == false:
    return 'Error negative cycle detected!'
  
  # Update the weights of G:
  for edge (u,v) in G.E:
    w(u,v) = w(u,v) + dists[s][u] - dists[s][v]
  
  # Matriz de distancias:
  MD = [][]
  
  # Run Dijkstra for each node of G:
  for u in G.V:
    MD[u] = Dijkstra(G,	u)
    
    # Fix the paths of MD:
    for v in G.V:
      MD[u][v] = MD[u][v] + dists[s][v] - dists[s][u]
    
  return MD

```
Complexidade no tempo: O(V² log(V) + V E)

---

Resumo da Aula:

- Repeated Squaring: O(V³ log(V))
- Floyd-Warshall: O(V³) e fácil de implementar
-	Johnson's: O(V² log(V) + V E) - melhor que Floyd-Warshall para grafos esparsos.

---

#Fim da Aula





