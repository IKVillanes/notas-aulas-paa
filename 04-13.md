
#PAA
#Wagner Meira

Mudança no calendário:

- 15/04 Aula de exercícios
- 22/04 Aula
- 27/04 Prova

O TP vai sair em breve, o prazo será para depois do dia 27, ainda não decidido.

---

### Programação Dinâmica:

Propriedades da programação dinâmica:

- Sobreposição ao espaço de soluções.
- Sub-estrutura ótima.

Exemplo com o cálculo da série de fibonacci:

f(n) = f(n-1) + f(n-2)
f(1) = f(0) = 1

Em outra aula discutimos sobre a resolução deste problema de forma recursiva.
Notamos que ele menos eficiente do que quando resolvido de forma iterativa pois
fib(n-k) era calculado multiplas vezes desnecessáriamente (só é preciso calcular uma).

Essa questão ocorre por sobreposição do espaço de solução.
Ou seja para calcular f(n) calcula-se f(n-1) e f(n-2)
mas f(n-1) precisa de f(n-2) para ser calculado, logo
o mesmo item do espaço é visitado mais de uma vez.

Em uma solução com programação dinâmica o que nós fariamos seria calcular 
cada item apenas na primeira vez e então salvar o resultado em um
local de fácil acesso para evitar calculos futuros.

Construir um algoritmo com programação dinâmica é feito em duas etapas:

### Fase Teórica:

Fases:

1. Definir o sub-problema  
   Entenda como serão as sub-chamadas de função,
   como serão os subproblemas.

2. Formule o problema recursivamente  
   Planeje quais subproblemas voce vai utilizar para gerar
   uma solução para o problema maior e como voce vai fazer isso.

3. Provar a recorrência  
   Prove, normalmente com indução, que sua recursão funciona.

### Fase de Implementação:

1. Analise a complexidade de tempo e espaço.

2. Escolhe a estrutura de memorização (para otimizar armazenamento e acesso).

3. Identificar dependencias entre sub-problemas.

4. Determinar a ordem de avaliação.

5. Implementar.

### Exemplo
Exemplo com o problema do escalonamento de intervalos ponderados:

Dadas n tarefas
- tempo de início Si
- tempo de fim Fi
- peso wi

Pede-se: encontrar o conjunto S de tarefas compatíveis de maior peso total.

Note que esse problema não pode ser solucionado de forma gulosa.
Porém pode ser resolvido de forma bastante eficiente com uma solução dinâmica.

A sub-estrutura ótima desse problema vem da idéia de que dado uma tarefa X
a partir do fim da primeira tarefa anterior que não colide com ela temos fechado um subproblema
cuja solução ótima será ótima independente de X ser incluido ou não.

Dessa forma basta identificar os subproblemas um a um e enumera-los.

Seja P(j), a tarefa com maior indice < j e compatível com j.

para cada j:

   Tenta os dois casos recursivamente:

  -> Tarefa j é incluída
   - Usa P(j)

  -> Tarefa j não é incluída
   - Usa j-1

O(j) = { 0, j=0
       { max { Wj + O(P(j)), O(j-1) }


Passo indutivo:

a. Não existe solução melhor para p(j) que O(p(j))
b. não existe solução melhor para j-1 que O(j-1)

a) => P(j) é compatível com J
b) => j-1 é compatível com !J

a) Existe k < P(j) | O(k) > O(P(j))
a) Existe k < j-1 | O(k) > O(j-1)

**Implementação:**

1. Análise de complexidade:  
 -> n tarefas => O(n) sub-problemas

- tempo ( O(n) )
- Espaço ( O(n) )

2. Escolhe a estrutura de memorização: Vetor indexado para j.

3. Identificar dependencias entre sub-problemas: P(j) < J => J depende de algum antecessor.

4. Determinar ordem de avaliação: 1..n

5. Implementação:

```javascipt
var i
for(i=0; i<=n; i++) {
  O(j) = max( Wj + O(P(j)), j-1 )
}
```

### Exemplo:
longest increasing subsqeuence (LIS)

{3,1,4,1,5,9,2,6,5,3}

LIS: 3 4 5 9
     1 4 5 6

O(1) = { 0, i=0
       { max { 1
             { max  de { 1 + OPT(j) } com j < i  e A[j] < A[i]

---

# Fim da aula!










